{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Members:\n",
    "    1 Sarang Padalkar\n",
    "    2 Priyank Aenugula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 180\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.linear_model import Ridge, RidgeCV, LassoCV\n",
    "training_data= pd.read_csv('dodgers_training.csv')\n",
    "test_data= pd.read_csv('dodgers_testing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocesssing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Encode the categorical variables using the one-hot encoding.\n",
    "categorical_col=['month', 'day_of_week', 'skies', 'bobblehead']\n",
    "\n",
    "##Removing all the columns which are not relevant.\n",
    "for col in training_data.columns:\n",
    "    if (col not in categorical_col) and (col !='attend' and col != 'temp'):\n",
    "        training_data.drop(col, axis=1, inplace=True)\n",
    "\n",
    "for col in test_data.columns:\n",
    "    if (col not in categorical_col) and (col !='attend' and col != 'temp'):\n",
    "        test_data.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##One-Hot Encoding\n",
    "training_data=pd.get_dummies(training_data,columns=categorical_col,prefix_sep=\"-\")\n",
    "test_data=pd.get_dummies(test_data,columns=categorical_col,prefix_sep=\"-\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Removing the extra columns in test data which are not there in training dataset.\n",
    "for col in test_data.columns:\n",
    "    if col not in training_data.columns:\n",
    "        test_data.drop(col, axis=1, inplace=True)\n",
    "\n",
    "##Adding the extra columns in test data which are present in training dataset.\n",
    "for col in training_data.columns:\n",
    "    if col not in test_data.columns:\n",
    "        test_data[col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56 entries, 0 to 55\n",
      "Data columns (total 20 columns):\n",
      "attend                   56 non-null int64\n",
      "temp                     56 non-null int64\n",
      "month-APR                56 non-null uint8\n",
      "month-AUG                56 non-null uint8\n",
      "month-JUL                56 non-null uint8\n",
      "month-JUN                56 non-null uint8\n",
      "month-MAY                56 non-null uint8\n",
      "month-OCT                56 non-null uint8\n",
      "month-SEP                56 non-null uint8\n",
      "day_of_week-Friday       56 non-null uint8\n",
      "day_of_week-Monday       56 non-null uint8\n",
      "day_of_week-Saturday     56 non-null uint8\n",
      "day_of_week-Sunday       56 non-null uint8\n",
      "day_of_week-Thursday     56 non-null uint8\n",
      "day_of_week-Tuesday      56 non-null uint8\n",
      "day_of_week-Wednesday    56 non-null uint8\n",
      "skies-Clear              56 non-null uint8\n",
      "skies-Cloudy             56 non-null uint8\n",
      "bobblehead-NO            56 non-null uint8\n",
      "bobblehead-YES           56 non-null uint8\n",
      "dtypes: int64(2), uint8(18)\n",
      "memory usage: 2.0 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25 entries, 0 to 24\n",
      "Data columns (total 20 columns):\n",
      "attend                   25 non-null int64\n",
      "temp                     25 non-null int64\n",
      "month-APR                25 non-null uint8\n",
      "month-AUG                25 non-null uint8\n",
      "month-JUL                25 non-null uint8\n",
      "month-JUN                25 non-null uint8\n",
      "month-MAY                25 non-null uint8\n",
      "month-OCT                25 non-null uint8\n",
      "month-SEP                25 non-null uint8\n",
      "day_of_week-Friday       25 non-null uint8\n",
      "day_of_week-Monday       25 non-null uint8\n",
      "day_of_week-Saturday     25 non-null uint8\n",
      "day_of_week-Sunday       25 non-null uint8\n",
      "day_of_week-Thursday     25 non-null int64\n",
      "day_of_week-Tuesday      25 non-null uint8\n",
      "day_of_week-Wednesday    25 non-null uint8\n",
      "skies-Clear              25 non-null uint8\n",
      "skies-Cloudy             25 non-null uint8\n",
      "bobblehead-NO            25 non-null uint8\n",
      "bobblehead-YES           25 non-null uint8\n",
      "dtypes: int64(3), uint8(17)\n",
      "memory usage: 1.1 KB\n",
      "None None\n"
     ]
    }
   ],
   "source": [
    "##Re-organizing the columns for testing data.\n",
    "cols=training_data.columns.tolist()\n",
    "test_data= test_data[cols]\n",
    "\n",
    "print((training_data.info()),(test_data.info()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Seprating the targets and features from the dataset.\n",
    "y_train = training_data['attend'].values\n",
    "X_train = training_data.drop('attend', axis=1).values\n",
    "X_test = test_data.drop('attend', axis=1).values\n",
    "y_test = test_data['attend'].values\n",
    "\n",
    "##Scaling the dataset.\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.71678692 -0.43759497  1.91485422 ... -0.49441323  0.31311215\n",
      "  -0.31311215]\n",
      " [-0.41074307 -0.43759497  1.91485422 ... -0.49441323  0.31311215\n",
      "  -0.31311215]\n",
      " [ 0.71678692 -0.43759497  1.91485422 ... -0.49441323 -3.19374388\n",
      "   3.19374388]\n",
      " ...\n",
      " [ 2.40808189 -0.43759497 -0.52223297 ... -0.49441323  0.31311215\n",
      "  -0.31311215]\n",
      " [-0.74900206  2.2852182  -0.52223297 ... -0.49441323  0.31311215\n",
      "  -0.31311215]\n",
      " [-0.29799007 -0.43759497 -0.52223297 ... -0.49441323  0.31311215\n",
      "  -0.31311215]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1. List the means and standard deviations of the encoded attributes before scaling.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orignal mean (Before Scaling) =  [7.36428571e+01 1.60714286e-01 2.14285714e-01 8.92857143e-02\n",
      " 8.92857143e-02 2.32142857e-01 1.78571429e-02 1.96428571e-01\n",
      " 1.78571429e-01 1.42857143e-01 1.60714286e-01 1.96428571e-01\n",
      " 8.92857143e-02 8.92857143e-02 1.42857143e-01 8.03571429e-01\n",
      " 1.96428571e-01 9.10714286e-01 8.92857143e-02]\n",
      "Orignal stds (Before Scaling) =  [8.86894375 0.36726721 0.4103259  0.2851557  0.2851557  0.42219966\n",
      " 0.13243212 0.39729635 0.38299305 0.34992711 0.36726721 0.39729635\n",
      " 0.2851557  0.2851557  0.34992711 0.39729635 0.39729635 0.2851557\n",
      " 0.2851557 ]\n"
     ]
    }
   ],
   "source": [
    "##Observe the dataset has been reduced to unit variance.\n",
    "print('Orignal mean (Before Scaling) = ', np.mean(X_train,axis=0))\n",
    "print('Orignal stds (Before Scaling) = ', np.std(X_train,axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2. What is the best L2 regularization coefficient? Provide the corresponding linear coefficients.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha for L2 regularization =  50.6\n",
      "Best coefs =  [  515.85380007  -273.56102806   457.54654532  -216.88248689\n",
      "  1102.57100111  -605.71237164   -75.78927596  -186.41964828\n",
      "    67.69322043  -835.67182144   490.25315842   238.14165655\n",
      "  -341.53918562  1070.28517076  -617.19884398   271.19412682\n",
      "  -271.19412682 -1145.58152754  1145.58152754]\n",
      "R2 =  0.33678367907497253\n"
     ]
    }
   ],
   "source": [
    "ridge = RidgeCV(cv=None, store_cv_values=True,alphas=np.linspace(0.1, 1000, 100))\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('Best alpha for L2 regularization = ', ridge.alpha_) \n",
    "print('Best coefs = ', (ridge.coef_))\n",
    "print('R2 = ', ridge.score(X_test_scaled,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 Regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>3. What is the best L1 regularization coefficient? Provide the corresponding linear coefficients.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha for L1 regularization =  616.2\n",
      "Best coefs =  [ 7.86580396e+02 -0.00000000e+00  6.49814486e+02 -0.00000000e+00\n",
      "  1.78831458e+03 -6.34820272e+01 -0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -1.02533744e+03  1.26702529e+02  0.00000000e+00\n",
      " -2.71433657e+02  1.32735001e+03 -7.50781549e+02  0.00000000e+00\n",
      " -0.00000000e+00 -2.53047199e+03  2.98833973e-12]\n",
      "R2 =  0.31801946357813315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2186127.1983425617, tolerance: 194226.85817297298\n",
      "  tol, rng, random, positive)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7171381.275317669, tolerance: 265827.9608432432\n",
      "  tol, rng, random, positive)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "lasso = LassoCV(cv=None, alphas=np.linspace(0.1, 1000, 100))\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "print('Best alpha for L1 regularization = ', lasso.alpha_) \n",
    "print('Best coefs = ', (lasso.coef_))\n",
    "print('R2 = ', lasso.score(X_test_scaled,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>4. What are the predictive attributes selected as a result of L1 regularization?</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prominent_attributes: {'temp': 786.5803963071144, 'month-AUG': 649.8144860334313, 'month-JUN': 1788.3145848633405, 'month-MAY': -63.48202720103302, 'day_of_week-Monday': -1025.3374368387701, 'day_of_week-Saturday': 126.70252889627709, 'day_of_week-Thursday': -271.43365745305755, 'day_of_week-Tuesday': 1327.3500057241483, 'day_of_week-Wednesday': -750.7815486029613, 'bobblehead-NO': -2530.4719937815066, 'bobblehead-YES': 2.9883397343967633e-12}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xf31d0f60f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prominent_attributes={}\n",
    "feature_names=training_data.drop('attend', axis=1).columns\n",
    "for x in range(len(lasso.coef_)):\n",
    "    if abs(lasso.coef_[x])>0:\n",
    "        prominent_attributes[feature_names[x]]=lasso.coef_[x]\n",
    "print (\"\\nProminent_attributes:\",prominent_attributes)\n",
    "df = pd.DataFrame(prominent_attributes,index=range(1))\n",
    "df.plot.bar(figsize=(16, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prominant predective attributes are: \n",
    "'temp', 'month-AUG', 'month-JUN', 'month-MAY', 'day_of_week-Monday', 'day_of_week-Saturday', 'day_of_week-Thursday', 'day_of_week-Tuesday', 'day_of_week-Wednesday', 'bobblehead-NO', 'bobblehead-YES'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Moder w/o Regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best coefs =  [ 1.48616556e+03 -2.83292980e+16 -3.16506469e+16 -2.19955952e+16\n",
      " -2.19955952e+16 -3.25665335e+16 -1.02152023e+16 -3.06456070e+16\n",
      "  3.46699476e+17  3.16766964e+17  3.32463868e+17  3.59647354e+17\n",
      "  2.58133494e+17  2.58133494e+17  3.16766964e+17 -8.57262940e+15\n",
      " -8.57262940e+15 -5.98449438e+16 -5.98449438e+16]\n",
      "R2 =  0.26189647112959846\n"
     ]
    }
   ],
   "source": [
    "from sklearn import  linear_model \n",
    "reg = linear_model.LinearRegression(fit_intercept=True)\n",
    "reg.fit(X_train_scaled, y_train)\n",
    "print('Best coefs = ', (reg.coef_))\n",
    "print('R2 = ', reg.score(X_test_scaled,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>5. For the models corresponding to the best L2 and L1 regularization coefficients \n",
    "list the following root-mean-square-error (RMSE): (1) RMSE on the training set, (2) \n",
    "expected prediction RMSE obtained during the cross-validation, (3) RMSE on the testing \n",
    "set. For the linear model without regularization list the following RMSE: (1) RMSE on \n",
    "the training set, and (2) RMSE on the testing set.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 - RMSE train =  5568.617925066778\n",
      "L1 - RMSE test =  6804.850359735517\n",
      "L2 - RMSE train =  5648.864216385291\n",
      "L2 - RMSE test =  6710.582066280917\n",
      "Expected prediction RMSE for L1 =  6753.243824779891\n",
      "Expected prediction RMSE for L2 =  6737.660948839507\n",
      "noreg - RMSE train =  5265.924411340254\n",
      "noreg - RMSE test =  7079.314887836486\n"
     ]
    }
   ],
   "source": [
    "###   RMSE for L1, L2 and linear regression w/o regularzation models.\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred_train_lasso=lasso.predict(X_train_scaled)\n",
    "y_pred_train_ridge=ridge.predict(X_train_scaled)\n",
    "y_pred_train_linear=reg.predict(X_train_scaled)\n",
    "\n",
    "y_pred_test_lasso=lasso.predict(X_test_scaled)\n",
    "y_pred_test_ridge=ridge.predict(X_test_scaled)\n",
    "y_pred_test_linear=reg.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "# L1\n",
    "print('L1 - RMSE train = ', (np.sqrt(mean_squared_error(y_pred_train_lasso,y_train))))\n",
    "print('L1 - RMSE test = ', (np.sqrt(mean_squared_error(y_pred_test_lasso,y_test))))\n",
    "\n",
    "# L2\n",
    "print('L2 - RMSE train = ', (np.sqrt(mean_squared_error(y_pred_train_ridge,y_train))))\n",
    "print('L2 - RMSE test = ', (np.sqrt(mean_squared_error(y_pred_test_ridge,y_test))))\n",
    "\n",
    "print(\"Expected prediction RMSE for L1 = \",np.min(np.sqrt(np.mean(lasso.mse_path_ ,axis =1))))\n",
    "print(\"Expected prediction RMSE for L2 = \",np.min(np.sqrt(np.mean(ridge.cv_values_,axis =0))))\n",
    "\n",
    "# no regularization\n",
    "print('noreg - RMSE train = ', (np.sqrt(mean_squared_error(y_pred_train_linear,y_train))))\n",
    "print('noreg - RMSE test = ', (np.sqrt(mean_squared_error(y_pred_test_linear,y_test))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>6. What observations can you make based on the above RMSE?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Root mean squared error (RMSE) values are the best way to judge the performance of the models. \n",
    "From the above values, we can infer the following:\n",
    " \n",
    "For training data, RMSE value for non-regularaized model is less than both L1(lasso) and L2(ridge) regularized models. However, L1(lasso) model performs better than L2(ridge)model. Thus we can infer that the linear regression model without regularization \"over-fits\" training data and hence has the lowest RMSE for the trainig dataset.\n",
    "\n",
    "For testing data, RMSE value for L2(ridge) model is less than both L1(lasso) and non-regularized model. Here the \"overfitting\" affects the non-regularized model when we use the model for predection on testing dataset. Whereas, we have used regularaization in L2(ridge) model and L1(Lasso) model, that helps them to overcome \"overfitting\" and perform better than linear non-regularized model. However, L2(ridge) model perfomrs better than L1(lasso model).\n",
    "\n",
    "\n",
    "If we compare the R2 scores on the testing dataset for the models, we notice that the L2 and L1 model scores are better than the non-regularized models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>7. Predict the attendance on a clear Monday in June when the expected temperature \n",
    "is 72 for all three models with and without bobbleheads. Does bobblehead promotion \n",
    "have an impact on the attendance?</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "temp = 72\n",
    "skies = clear\n",
    "month = June\n",
    "day_of_week = monday\n",
    "bubbleheads = N\n",
    "'''\n",
    "\n",
    "X_test_wobubble=scaler.transform(np.array([72,0,0,0,1,0,0,0,0,1,0,0,0,0,0,1,0,1,0]).reshape(1, -1))\n",
    "\n",
    "\n",
    "y_pred_test_lasso_wob=lasso.predict(X_test_wobubble)\n",
    "y_pred_test_ridge_wob=ridge.predict(X_test_wobubble)\n",
    "y_pred_test_linear_wob=reg.predict(X_test_wobubble)\n",
    "\n",
    "'''\n",
    "temp = 72\n",
    "skies = clear\n",
    "month = June\n",
    "day_of_week = monday\n",
    "bubbleheads = Y\n",
    "'''\n",
    "\n",
    "X_test_wbubble=scaler.transform(np.array([72,0,0,0,1,0,0,0,0,1,0,0,0,0,0,1,0,0,1]).reshape(1, -1))\n",
    "\n",
    "\n",
    "y_pred_test_lasso_wb=lasso.predict(X_test_wbubble)\n",
    "y_pred_test_ridge_wb=ridge.predict(X_test_wbubble)\n",
    "y_pred_test_linear_wb=reg.predict(X_test_wbubble)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attendence W/o bubblehead:\n",
      "L1 -  [41542.63460448] \n",
      "L2 - [40638.44252892] \n",
      "Non-Reg - [41217.82779728]\n",
      "\n",
      "Attendence with bubblehead:\n",
      "L1 -  [50416.63557481] \n",
      "L2 - [48673.22150451] \n",
      "Non-Reg - [51201.82779728]\n"
     ]
    }
   ],
   "source": [
    "print(\"Attendence W/o bubblehead:\\nL1 - \",y_pred_test_lasso_wob,\"\\nL2 -\",y_pred_test_ridge_wob,\"\\nNon-Reg -\",y_pred_test_linear_wob)\n",
    "print(\"\\nAttendence with bubblehead:\\nL1 - \",y_pred_test_lasso_wb,\"\\nL2 -\",y_pred_test_ridge_wb,\"\\nNon-Reg -\",y_pred_test_linear_wb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Observation</b>: The bubblehead has a positive impact on the Attendance of the game, i.e predicted attendence for a game with bubble head is more than the games without bubblehead."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
